### Introducción a la Álgebra Lineal I
El álgebra lineal es una rama de las matemáticas que se encarga del estudio de **vectores**, **espacios vectoriales** y **transformaciones lineales**. En pocas palabras, es el lenguaje de las matemáticas para describir y manipular cosas que se mueven o se transforman en múltiples dimensiones, como vectores en el espacio tridimensional. A diferencia del álgebra que viste en la prepa, donde se resuelven ecuaciones con una o dos variables (x, y), aquí trabajamos con sistemas de ecuaciones con muchísimas variables y con objetos que representan cantidades y direcciones.

#### ¿Por qué es importante para Ciencias de la Computación?

No es exageración decir que el álgebra lineal está detrás de casi todo lo que ves en el campo. Por ejemplo:

- **Gráficas por computadora**: Para rotar, escalar y mover objetos 3D en un videojuego o en un programa de diseño, se usan **transformaciones lineales** representadas por matrices.
    
- **Inteligencia Artificial y Machine Learning**: Los algoritmos de aprendizaje profundo manejan enormes conjuntos de datos organizados como matrices y vectores, y las operaciones clave, como la multiplicación de matrices, son el corazón de su funcionamiento.
    
- **Análisis de datos**: Para encontrar patrones en grandes bases de datos (por ejemplo, en las redes sociales), se usan técnicas como el **Análisis de Componentes Principales** que se basan totalmente en conceptos de álgebra lineal.


En resumen, el álgebra lineal te da las herramientas para entender y programar sistemas que lidian con datos de alta dimensión, que es el pan de cada día en tu carrera.

#### Conceptos clave que veremos

A lo largo del curso, nos vamos a enfocar en los siguientes temas:

1. **Espacios vectoriales**: Imagina un plano 2D o un espacio 3D. Un espacio vectorial es una generalización de esto. No solo son vectores que puedes dibujar, sino que son colecciones de "vectores" de cualquier tipo (funciones, polinomios, etc.) que cumplen ciertas reglas para que puedas sumarlos y multiplicarlos por escalares (números).
    
2. **Sistemas de ecuaciones lineales**: Resolver sistemas de ecuaciones no es solo encontrar el valor de x y y. Aquí, aprenderemos métodos como la **eliminación gaussiana** para encontrar las soluciones de sistemas grandes de forma sistemática.
    
3. **Transformaciones lineales**: Piensa en una transformación como una función que "mueve" vectores de un espacio a otro de una forma especial. Por ejemplo, una rotación o una reflexión. Estas transformaciones se pueden representar con **matrices**.
    
4. **Producto escalar**: Esta operación te permite medir cosas como la longitud de un vector o el ángulo entre dos vectores. Es la base para entender la ortogonalidad (la noción de que dos vectores son perpendiculares).
    
5. **Determinantes**: Es un valor escalar que nos da información clave sobre una matriz, como si la transformación que representa "aplasta" el espacio a una dimensión menor o si tiene inversa.
    
6. **Eigenvalores y eigenvectores**: Son conceptos muy potentes que te ayudan a entender la "dirección" principal de una transformación. En ciencia de datos, esto es crucial para reducir la dimensionalidad de los problemas.

